# Week 1 — Build Your First LLM Product: Exploring Top Models & Transformers

## 🧭 목차

1. [LLM 엔지니어의 핵심 역량](#llm-엔지니어의-핵심-역량)
2. [프론티어 vs 오픈소스 모델](#프론티어-vs-오픈소스-모델)
3. [토크나이제이션과 컨텍스트 윈도우](#토크나이제이션과-컨텍스트-윈도우)
4. [API와 로컬 모델 활용](#api와-로컬-모델-활용)
5. [시스템 & 사용자 프롬프트](#시스템--사용자-프롬프트)
6. [핵심 요약](#핵심-요약)
7. [코드](#코드)

---

## LLM 엔지니어의 핵심 역량

* **모델 이해력**:
  다양한 아키텍처와 모달리티(텍스트, 이미지, 오디오 등),
  오픈소스 vs 폐쇄형 모델의 장단점을 이해해야 함.

* **주요 도구 스택**

  * **Hugging Face** (모델 관리 및 토크나이저)
  * **LangChain** (에이전트 구성 및 논리 연결)
  * **Gradio** (빠른 UI 프로토타이핑)
  * **Weights & Biases** (실험 추적 및 관리)
  * **Modal** (확장 가능한 배포)

* **핵심 기술**: Retrieval-Augmented Generation (RAG), 파인튜닝, 멀티 에이전트 오케스트레이션

* **마인드셋**: 실험 + 벤치마킹 + 반복 개선

---

## 프론티어 vs 오픈소스 모델

* **프론티어 모델**: GPT-4, Claude 3.5, Gemini 1.5 Pro — 높은 성능, 유료, 폐쇄형
* **오픈소스 모델**: Llama 3.2, Gemma, Qwen 2.5, Mistral 7B — 자유도 높고 자가 호스팅 가능하지만 성능은 다소 낮음
* **실습 예시**: Ollama를 통해 로컬에서 각 모델의 속도·추론력 비교
* **핵심 인사이트**: 모델 선택은 **성능, 지연시간, 프라이버시, 비용** 간의 균형 결정

---

## 토크나이제이션과 컨텍스트 윈도우

* **토큰(Token)**: 모델이 처리하는 기본 단위 (약 4글자 또는 0.75단어)
* **기본 공식**: 1,000토큰 ≈ 750단어
* **토크나이저 특징**

  * 일반 단어는 1:1 매핑
  * 복합 단어나 드문 단어는 분할됨 (*handcrafted → hand + crafted*)
  * 숫자는 3자리 단위로 나뉨
* **컨텍스트 윈도우**: 모델이 한 번에 “기억”할 수 있는 최대 토큰 수

  * 커질수록 장문 추론에 강하지만, 메모리·비용 증가

---

## API와 로컬 모델 활용

* **LLM 사용 방식 3가지**

  1. **클라우드 API** — OpenAI, Anthropic, Gemini (유료·확장성 높음)
  2. **오픈소스 코드** — Hugging Face + PyTorch (Colab GPU 사용 가능)
  3. **로컬 컴파일 모델** — Ollama (개인정보 안전, 속도 빠름)

* **트레이드오프**

  * Cloud = 제어력 ↑, 비용 ↑, 프라이버시 ↓
  * Local = 프라이버시 ↑, 속도 ↑, 유연성 ↓

---

## 시스템 & 사용자 프롬프트

* **System prompt**: AI의 성격·톤·규칙 설정 (예: “유머러스하게”, “스페인어로 답변”)
* **User prompt**: 실제 지시문이나 질문
* **멀티모델 체이닝 예시**: 영어 생성 → 번역 모델 호출
* **핵심 포인트**: 구조화된 프롬프트 설계는 향후 에이전트 시스템의 기반

---

## 핵심 요약

* **“직접 만들어보며 배우는 것”**이 핵심 — 모든 개념은 실습과 연결됨.
* **토큰과 컨텍스트 윈도우** 이해는 비용·성능 최적화의 핵심.
* **프론티어 vs 오픈소스 모델 비교**는 판단력을 키움.
* **프롬프트 엔지니어링 + API 조합 능력**은 에이전트 설계의 기초.

---

## 코드

<details>
<summary>코드 보기</summary>

```python
# ============================================================
# 🧠 Week 1 — 주요 코드 패턴
# ============================================================

# (1) Core LLM Call
# 기본 LLM 호출 구조 — 메시지 정의 → 모델 호출 → 결과 추출
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Summarize this article in markdown."}
]
resp = client.chat.completions.create(model="gpt-4o-mini", messages=messages)
print(resp.choices[0].message.content)

# ------------------------------------------------------------

# (2) System / User Prompt Structure
# System: 규칙·톤 / User: 작업 지시
SYSTEM_PROMPT = "You are an expert summarizer. Return concise markdown."
USER_PROMPT = f"Summarize:\n\n{raw_text}"
messages = [
    {"role": "system", "content": SYSTEM_PROMPT},
    {"role": "user", "content": USER_PROMPT}
]

# ------------------------------------------------------------

# (3) Summarization Helper
# 여러 작업에 활용 가능한 요약 유틸리티
def summarize(text):
    msgs = [
        {"role": "system", "content": "Summarize key ideas in markdown bullets."},
        {"role": "user", "content": text}
    ]
    return client.chat.completions.create(
        model="gpt-4o-mini", messages=msgs
    ).choices[0].message.content

# ------------------------------------------------------------

# (4) Streaming Render
# 토큰 단위로 실시간 출력 — 디버깅과 데모에 유용
from IPython.display import Markdown, display
view, buf = display(Markdown(""), display_id=True), ""
for chunk in stream:      # chunk = LLM의 부분 응답
    buf += chunk
    view.update(Markdown(buf))

# ------------------------------------------------------------

# (5) Generate → Transform Pipeline
# 두 번의 간단한 LLM 호출: 생성 → 변환
# Generate: 초안 생성 (요약, 보고서, 설명)
# Transform: 수정, 번역, 재포맷 등 후처리
draft = summarize(source_text)  # Generate
final = client.chat.completions.create(  # Transform
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "Translate this to Spanish and keep markdown."},
        {"role": "user", "content": draft}
    ]
).choices[0].message.content

# 결과: 생성 → 변환의 단순하지만 강력한 워크플로우
# ============================================================
```

</details>
