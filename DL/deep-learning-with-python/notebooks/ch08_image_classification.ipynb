{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463af3e3",
   "metadata": {},
   "source": [
    "### 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95321f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def backend(line, cell):\n",
    "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
    "    if current == required:\n",
    "        get_ipython().run_cell(cell)\n",
    "    else:\n",
    "        print(\n",
    "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
    "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe415c4",
   "metadata": {},
   "source": [
    "### 2. Download and Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "kagglehub.login()\n",
    "download_path = kagglehub.competition_download(\"dogs-vs-cats\")\n",
    "\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(download_path + \"/train.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148eed9",
   "metadata": {},
   "source": [
    "### 3. Prepare Dataset (Train / Validation / Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3dbd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"train\")\n",
    "new_base_dir = pathlib.Path(\"dogs_vs_cats_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13ac3a",
   "metadata": {},
   "source": [
    "### 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756971497.342840  385047 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1756971497.342858  385047 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "batch_size = 64\n",
    "image_size = (180, 180)\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\", image_size=image_size, batch_size=batch_size\n",
    ")\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\", image_size=image_size, batch_size=batch_size\n",
    ")\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\", image_size=image_size, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fef218",
   "metadata": {},
   "source": [
    "### 5. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c1a6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-09-04 14:38:17,527:jax._src.xla_bridge:1018: Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1756971497.528312  385047 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1756971497.528943  385047 service.cc:145] XLA service 0x309656550 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756971497.528952  385047 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1756971497.529825  385047 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1756971497.529836  385047 mps_client.cc:384] XLA backend will use up to 11452841984 bytes on device 0 for SimpleAllocator.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "]\n",
    "\n",
    "def data_augmentation(images, targets):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    return images, targets\n",
    "\n",
    "augmented_train_dataset = train_dataset.map(\n",
    "    data_augmentation, num_parallel_calls=8\n",
    ")\n",
    "augmented_train_dataset = augmented_train_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9ba60",
   "metadata": {},
   "source": [
    "### 6. Load Pretrained Model (Xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ddf5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras_hub\n",
    "\n",
    "conv_base = keras_hub.models.Backbone.from_preset(\n",
    "    \"xception_41_imagenet\",\n",
    "    trainable=False,\n",
    ")\n",
    "preprocessor = keras_hub.layers.ImageConverter.from_preset(\n",
    "    \"xception_41_imagenet\",\n",
    "    image_size=(180, 180),\n",
    ")\n",
    "conv_base.trainable = False\n",
    "len(conv_base.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9504bf04",
   "metadata": {},
   "source": [
    "### 7. Build Model (Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934e6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = preprocessor(inputs)\n",
    "x = conv_base(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af4251",
   "metadata": {},
   "source": [
    "### 8. Train Model (Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b868563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chan/projects/keras-dl/.venv/lib/python3.11/site-packages/jax/_src/interpreters/mlir.py:1153: UserWarning: Some donated buffers were not usable: ShapedArray(float32[2048,256]), ShapedArray(float32[256]), ShapedArray(float32[256,1]), ShapedArray(float32[1]), ShapedArray(float32[3,3,3,32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[3,3,32,64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,64,1]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[3,3,1024,1]), ShapedArray(float32[1,1,1024,1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[3,3,1536,1]), ShapedArray(float32[1,1,1536,2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(uint32[2]), ShapedArray(int32[]), ShapedArray(float32[]), ShapedArray(float32[2048,256]), ShapedArray(float32[2048,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256,1]), ShapedArray(float32[256,1]), ShapedArray(float32[1]), ShapedArray(float32[1]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]).\n",
      "Donation is not implemented for ('METAL',).\n",
      "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
      "  warnings.warn(\"Some donated buffers were not usable:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.8861 - loss: 0.2317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chan/projects/keras-dl/.venv/lib/python3.11/site-packages/jax/_src/interpreters/mlir.py:1153: UserWarning: Some donated buffers were not usable: ShapedArray(float32[2048,256]), ShapedArray(float32[256]), ShapedArray(float32[256,1]), ShapedArray(float32[1]), ShapedArray(float32[3,3,3,32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[3,3,32,64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,64,1]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[3,3,1024,1]), ShapedArray(float32[1,1,1024,1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[3,3,1536,1]), ShapedArray(float32[1,1,1536,2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(uint32[2]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]).\n",
      "Donation is not implemented for ('METAL',).\n",
      "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
      "  warnings.warn(\"Some donated buffers were not usable:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 809ms/step - accuracy: 0.9405 - loss: 0.1686 - val_accuracy: 0.9780 - val_loss: 0.0800\n",
      "Epoch 2/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 771ms/step - accuracy: 0.9660 - loss: 0.0866 - val_accuracy: 0.9800 - val_loss: 0.0749\n",
      "Epoch 3/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 821ms/step - accuracy: 0.9525 - loss: 0.1594 - val_accuracy: 0.9810 - val_loss: 0.0598\n",
      "Epoch 4/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 862ms/step - accuracy: 0.9725 - loss: 0.0748 - val_accuracy: 0.9820 - val_loss: 0.0654\n",
      "Epoch 5/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 891ms/step - accuracy: 0.9815 - loss: 0.0603 - val_accuracy: 0.9830 - val_loss: 0.0658\n",
      "Epoch 6/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 910ms/step - accuracy: 0.9790 - loss: 0.0678 - val_accuracy: 0.9830 - val_loss: 0.0588\n",
      "Epoch 7/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 930ms/step - accuracy: 0.9775 - loss: 0.0462 - val_accuracy: 0.9800 - val_loss: 0.0571\n",
      "Epoch 8/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 917ms/step - accuracy: 0.9845 - loss: 0.0451 - val_accuracy: 0.9840 - val_loss: 0.0542\n",
      "Epoch 9/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 932ms/step - accuracy: 0.9830 - loss: 0.0462 - val_accuracy: 0.9860 - val_loss: 0.0514\n",
      "Epoch 10/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 943ms/step - accuracy: 0.9810 - loss: 0.0552 - val_accuracy: 0.9780 - val_loss: 0.0694\n",
      "Epoch 11/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 976ms/step - accuracy: 0.9825 - loss: 0.0518 - val_accuracy: 0.9860 - val_loss: 0.0499\n",
      "Epoch 12/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 951ms/step - accuracy: 0.9830 - loss: 0.0473 - val_accuracy: 0.9870 - val_loss: 0.0448\n",
      "Epoch 13/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 947ms/step - accuracy: 0.9880 - loss: 0.0329 - val_accuracy: 0.9830 - val_loss: 0.0496\n",
      "Epoch 14/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.9840 - loss: 0.0457 - val_accuracy: 0.9850 - val_loss: 0.0513\n",
      "Epoch 15/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.9850 - loss: 0.0394 - val_accuracy: 0.9860 - val_loss: 0.0524\n",
      "Epoch 16/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.9825 - loss: 0.0582 - val_accuracy: 0.9750 - val_loss: 0.0903\n",
      "Epoch 17/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.9855 - loss: 0.0499 - val_accuracy: 0.9800 - val_loss: 0.0627\n",
      "Epoch 18/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.9890 - loss: 0.0326 - val_accuracy: 0.9850 - val_loss: 0.0549\n",
      "Epoch 19/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.9845 - loss: 0.0442 - val_accuracy: 0.9800 - val_loss: 0.0630\n",
      "Epoch 20/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.9785 - loss: 0.0577 - val_accuracy: 0.9850 - val_loss: 0.0517\n",
      "Epoch 21/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9880 - loss: 0.0460 - val_accuracy: 0.9860 - val_loss: 0.0543\n",
      "Epoch 22/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9915 - loss: 0.0272 - val_accuracy: 0.9840 - val_loss: 0.0581\n",
      "Epoch 23/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9905 - loss: 0.0297 - val_accuracy: 0.9770 - val_loss: 0.0589\n",
      "Epoch 24/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9875 - loss: 0.0335 - val_accuracy: 0.9850 - val_loss: 0.0627\n",
      "Epoch 25/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.9880 - loss: 0.0354 - val_accuracy: 0.9850 - val_loss: 0.0604\n",
      "Epoch 26/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.9865 - loss: 0.0368 - val_accuracy: 0.9870 - val_loss: 0.0548\n",
      "Epoch 27/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.9850 - loss: 0.0377 - val_accuracy: 0.9820 - val_loss: 0.0631\n",
      "Epoch 28/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.9875 - loss: 0.0332 - val_accuracy: 0.9760 - val_loss: 0.0787\n",
      "Epoch 29/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.9830 - loss: 0.0461 - val_accuracy: 0.9850 - val_loss: 0.0597\n",
      "Epoch 30/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.9850 - loss: 0.0400 - val_accuracy: 0.9770 - val_loss: 0.0856\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "    )\n",
    "]\n",
    "history = model.fit(\n",
    "    augmented_train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c9b80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chan/projects/keras-dl/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 318 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/chan/projects/keras-dl/.venv/lib/python3.11/site-packages/jax/_src/interpreters/mlir.py:1153: UserWarning: Some donated buffers were not usable: ShapedArray(float32[3,3,3,32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[3,3,32,64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,64,1]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[3,3,1024,1]), ShapedArray(float32[1,1,1024,1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[3,3,1536,1]), ShapedArray(float32[1,1,1536,2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048,256]), ShapedArray(float32[256]), ShapedArray(float32[256,1]), ShapedArray(float32[1]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(uint32[2]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]).\n",
      "Donation is not implemented for ('METAL',).\n",
      "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
      "  warnings.warn(\"Some donated buffers were not usable:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.9845 - loss: 0.0483\n",
      "Test accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "test_model = keras.models.load_model(\n",
    "    \"feature_extraction_with_data_augmentation.keras\"\n",
    ")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea1fbd2",
   "metadata": {},
   "source": [
    "### 9. Prepare for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4f2505",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in conv_base.layers:\n",
    "    if isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfa249",
   "metadata": {},
   "source": [
    "### 10. Train Model (Fine-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945debed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chan/projects/keras-dl/.venv/lib/python3.11/site-packages/jax/_src/interpreters/mlir.py:1153: UserWarning: Some donated buffers were not usable: ShapedArray(float32[3,3,1536,1]), ShapedArray(float32[1,1,1536,2048]), ShapedArray(float32[2048,256]), ShapedArray(float32[256]), ShapedArray(float32[256,1]), ShapedArray(float32[1]), ShapedArray(float32[3,3,3,32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[3,3,32,64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,64,1]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[3,3,1024,1]), ShapedArray(float32[1,1,1024,1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(uint32[2]), ShapedArray(int32[]), ShapedArray(float32[]), ShapedArray(float32[3,3,1536,1]), ShapedArray(float32[3,3,1536,1]), ShapedArray(float32[1,1,1536,2048]), ShapedArray(float32[1,1,1536,2048]), ShapedArray(float32[2048,256]), ShapedArray(float32[2048,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256,1]), ShapedArray(float32[256,1]), ShapedArray(float32[1]), ShapedArray(float32[1]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]).\n",
      "Donation is not implemented for ('METAL',).\n",
      "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
      "  warnings.warn(\"Some donated buffers were not usable:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - accuracy: 0.9872 - loss: 0.0301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chan/projects/keras-dl/.venv/lib/python3.11/site-packages/jax/_src/interpreters/mlir.py:1153: UserWarning: Some donated buffers were not usable: ShapedArray(float32[3,3,1536,1]), ShapedArray(float32[1,1,1536,2048]), ShapedArray(float32[2048,256]), ShapedArray(float32[256]), ShapedArray(float32[256,1]), ShapedArray(float32[1]), ShapedArray(float32[3,3,3,32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[32]), ShapedArray(float32[3,3,32,64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[64]), ShapedArray(float32[3,3,64,1]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[1,1,64,128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[128]), ShapedArray(float32[3,3,128,1]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[1,1,128,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,1]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[1,1,256,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[728]), ShapedArray(float32[3,3,728,1]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1,1,728,1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[1024]), ShapedArray(float32[3,3,1024,1]), ShapedArray(float32[1,1,1024,1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[1536]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(float32[2048]), ShapedArray(uint32[2]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]).\n",
      "Donation is not implemented for ('METAL',).\n",
      "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
      "  warnings.warn(\"Some donated buffers were not usable:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.9870 - loss: 0.0310 - val_accuracy: 0.9820 - val_loss: 0.0672\n",
      "Epoch 2/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9905 - loss: 0.0264 - val_accuracy: 0.9840 - val_loss: 0.0653\n",
      "Epoch 3/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9920 - loss: 0.0196 - val_accuracy: 0.9850 - val_loss: 0.0632\n",
      "Epoch 4/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3s/step - accuracy: 0.9930 - loss: 0.0264 - val_accuracy: 0.9840 - val_loss: 0.0619\n",
      "Epoch 5/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.9905 - loss: 0.0237 - val_accuracy: 0.9850 - val_loss: 0.0587\n",
      "Epoch 6/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 0.9900 - loss: 0.0253 - val_accuracy: 0.9860 - val_loss: 0.0569\n",
      "Epoch 7/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.9890 - loss: 0.0279 - val_accuracy: 0.9850 - val_loss: 0.0581\n",
      "Epoch 8/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - accuracy: 0.9950 - loss: 0.0182 - val_accuracy: 0.9870 - val_loss: 0.0550\n",
      "Epoch 9/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.9915 - loss: 0.0216 - val_accuracy: 0.9870 - val_loss: 0.0537\n",
      "Epoch 10/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9905 - loss: 0.0267 - val_accuracy: 0.9870 - val_loss: 0.0539\n",
      "Epoch 11/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9920 - loss: 0.0230 - val_accuracy: 0.9870 - val_loss: 0.0527\n",
      "Epoch 12/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.9930 - loss: 0.0186 - val_accuracy: 0.9870 - val_loss: 0.0529\n",
      "Epoch 13/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.9915 - loss: 0.0249 - val_accuracy: 0.9840 - val_loss: 0.0535\n",
      "Epoch 14/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.9920 - loss: 0.0220 - val_accuracy: 0.9850 - val_loss: 0.0538\n",
      "Epoch 15/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.9945 - loss: 0.0184 - val_accuracy: 0.9850 - val_loss: 0.0533\n",
      "Epoch 16/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 0.9905 - loss: 0.0208 - val_accuracy: 0.9850 - val_loss: 0.0528\n",
      "Epoch 17/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.9940 - loss: 0.0184 - val_accuracy: 0.9840 - val_loss: 0.0555\n",
      "Epoch 18/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step - accuracy: 0.9940 - loss: 0.0195 - val_accuracy: 0.9840 - val_loss: 0.0539\n",
      "Epoch 19/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3s/step - accuracy: 0.9920 - loss: 0.0220 - val_accuracy: 0.9840 - val_loss: 0.0534\n",
      "Epoch 20/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.9935 - loss: 0.0206 - val_accuracy: 0.9850 - val_loss: 0.0538\n",
      "Epoch 21/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.9950 - loss: 0.0162 - val_accuracy: 0.9830 - val_loss: 0.0545\n",
      "Epoch 22/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3s/step - accuracy: 0.9970 - loss: 0.0116 - val_accuracy: 0.9830 - val_loss: 0.0537\n",
      "Epoch 23/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.9965 - loss: 0.0174 - val_accuracy: 0.9840 - val_loss: 0.0532\n",
      "Epoch 24/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.9950 - loss: 0.0156 - val_accuracy: 0.9850 - val_loss: 0.0506\n",
      "Epoch 25/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9945 - loss: 0.0174 - val_accuracy: 0.9850 - val_loss: 0.0499\n",
      "Epoch 26/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.9920 - loss: 0.0172 - val_accuracy: 0.9850 - val_loss: 0.0503\n",
      "Epoch 27/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.9935 - loss: 0.0174 - val_accuracy: 0.9860 - val_loss: 0.0503\n",
      "Epoch 28/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.9955 - loss: 0.0149 - val_accuracy: 0.9850 - val_loss: 0.0496\n",
      "Epoch 29/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.9970 - loss: 0.0111 - val_accuracy: 0.9850 - val_loss: 0.0493\n",
      "Epoch 30/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.9935 - loss: 0.0187 - val_accuracy: 0.9850 - val_loss: 0.0489\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"fine_tuning.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "    )\n",
    "]\n",
    "history = model.fit(\n",
    "    augmented_train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a37b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 537ms/step - accuracy: 0.9865 - loss: 0.0479\n",
      "Test accuracy: 0.987\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"fine_tuning.keras\")\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0cc66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-dl (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
